<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: ruby | semantic art]]></title>
  <link href="http://blog.semanticart.com/blog/blog/categories/ruby/atom.xml" rel="self"/>
  <link href="http://blog.semanticart.com/blog/"/>
  <updated>2015-05-17T20:32:18-04:00</updated>
  <id>http://blog.semanticart.com/blog/</id>
  <author>
    <name><![CDATA[Jeffrey Chupp]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Untwisting a Hypertext Narrative - PEG to the Rescue!]]></title>
    <link href="http://blog.semanticart.com/blog/blog/2014/01/19/untwisting-a-hypertext-narrative-peg-to-the-rescue/"/>
    <updated>2014-01-19T13:18:00-05:00</updated>
    <id>http://blog.semanticart.com/blog/blog/2014/01/19/untwisting-a-hypertext-narrative-peg-to-the-rescue</id>
    <content type="html"><![CDATA[<p>In this post you&rsquo;ll learn why I think Parsing Expression Grammars are awesome and see an example of how I built one to scratch an itch.</p>

<h2>The Itch</h2>

<p>After spending some time <a href="http://blog.semanticart.com/blog/2014/01/11/writing-hypertext-fiction-in-markdown/">writing Choose Your Own Adventure-style books in markdown</a>, I quickly realized there were some tools missing that could greatly improve the writing process. A few missing items were:</p>

<ol>
<li>Knowing if there are any unreachable sections that have been orphaned in the writing process.</li>
<li>Being able to see all the branches within a book.</li>
<li>Knowing each branch is coherent by having an easy way to read through them.</li>
</ol>


<p>&ldquo;Never fear,&rdquo; I say to myself, &ldquo;I can just write some code to parse the markdown files and pluck out the paths. This will be easy.&rdquo;</p>

<p>As a quick reminder, the format for a single section looks something like this:</p>

<p>```</p>

<h1>Something isn&rsquo;t right here. {#intro}</h1>

<p>You hear a phone ringing.</p>

<ul>
<li><a href="#phone">pick up phone</a></li>
<li><a href="#ignore-phone">do not answer</a></li>
<li><a href="#fire">set yourself on fire</a>
```</li>
</ul>


<p>(Headers specify new sections starting and have some anchor. Links direct you to new sections.)</p>

<p>There are plenty of ways to slurp in a story file and parse it. You could write a naive line-by-line loop that breaks it into sections based on the presence of a header and then parse the links within sections with substring matching. You could write some complicated regular expression because <a href="http://stackoverflow.com/a/1732454">we all know how much fun regular expressions can become</a>. Or you could do something saner like write a <a href="https://en.wikipedia.org/wiki/Parsing_expression_grammar">parsing expression grammar</a> (hereafter PEG).</p>

<h2>Why a PEG?</h2>

<p>Generally, a regex makes for a beautiful collection of cryptic ascii art that you&rsquo;ll either comment-to-death or be confused by when you stumble across it weeks or months later. PEGs take a different approach and instead seek define <a href="https://en.wikipedia.org/wiki/Parsing_expression_grammar">&ldquo;a formal language in terms of a set of rules for recognizing strings in the language.&rdquo;</a> Because they&rsquo;re a set of rules, you can slowly TDD your way up from parsing a single phrase to parsing an entire document (or at least the parts you care about).</p>

<p>(It is worth mentioning that because the format here is pretty trivial, either the naive line-by-line solution or a regex is fine. PEGs are without a doubt the right choice IMHO for complicated grammars.)</p>

<h2>Show me some code</h2>

<p>We&rsquo;ll be using <a href="http://kschiess.github.io/parslet/">Parslet</a> to write our PEG. Parslet provides a succinct syntax and exponentially better error messages than other competing ruby PEGs (<code>parse_with_debug</code> is my friend). My biggest complaint about Parslet is that the documentation was occasionally lacking, but it only slowed things down a bit &ndash; and there&rsquo;s an <a href="http://kschiess.github.io/parslet/contribute.html">IRC channel and mailing list</a>.</p>

<p>Let&rsquo;s start off simple, just parsing the links out of a single section of markdown. Being a TDD'er, we&rsquo;ll write a few simple tests first (in MiniTest::Spec):</p>

<p>```ruby
describe LinkParser do
  def parse(input)</p>

<pre><code>LinkParser.new.parse(input)
</code></pre>

<p>  end</p>

<p>  it &ldquo;can match a single link&rdquo; do</p>

<pre><code>parsed = parse("[some link name](#some-href)").first

assert_equal "some-href",
  parsed[:id]
</code></pre>

<p>  end</p>

<p>  it &ldquo;can match a single link surrounded by content&rdquo; do</p>

<pre><code>parsed = parse("
  hey there [some link name](#some-href)
  some content
").first

assert_equal "some-href",
  parsed[:id]
</code></pre>

<p>  end</p>

<p>  it &ldquo;can match a multiple links surrounded by content&rdquo; do</p>

<pre><code>parsed = parse("
  hey there [some link name](#some-href)
  some content with a link [another](#new-href) and [another still](#last) ok?
")

assert_equal ["some-href", "new-href", "last"],
  parsed.map{|s| s[:id].to_s}
</code></pre>

<p>  end
end
```</p>

<p>And the working implementation of LinkParser:</p>

<p>```ruby
class LinkParser &lt; Parslet::Parser
  rule(:link_text) { str(&ldquo;[&rdquo;) >> (str(&lsquo;]&rsquo;).absent? >> any).repeat >> str(&lsquo;]&rsquo;) }
  rule(:link_href) {</p>

<pre><code>  str('(#') &gt;&gt; (str(')').absent? &gt;&gt; any).repeat.as(:id) &gt;&gt; str(')')
</code></pre>

<p>  }
  rule(:link)      { link_text >> link_href }
  rule(:non_link)  { (link.absent? >> any).repeat }
  rule(:content)   { (non_link >> link >> non_link).repeat }</p>

<p>  root(:content)
end
```</p>

<p>&ldquo;Foul,&rdquo; you cry, &ldquo;this is much more complicated than a regular expression!&rdquo; And I reply &ldquo;Yes, but it is also more intelligible long-term as you build upon it.&rdquo; You don&rsquo;t look completely satisfied, but you&rsquo;ll continue reading.</p>

<p>It is worth noting that everything has a name:</p>

<ul>
<li>link_text encompasses everything between the two brackets in the markdown link.</li>
<li>link_href is the content within the parens. Because we are specifically linking only to anchors, we also include the # and then we&rsquo;ll name the id we&rsquo;re linking to via <code>as</code>.</li>
<li>link is just link_text + link_href</li>
<li>non_link is anything that isn&rsquo;t a link. It could be other markdown or plain text. It may or may not actually contain any characters at all.</li>
<li>content is the whole markdown content. We can see it is made up of some number of the following: non_link + link + non_link</li>
</ul>


<p>We&rsquo;ve specified that &ldquo;content&rdquo; is our root so the parser starts there.</p>

<h2>The Scratch: Adding the 3 missing features</h2>

<p>Now we have an easy way to extract links from sections within a story. We&rsquo;ll be able to leverage this to map the branches and solve all three problems.</p>

<p>But in order to break the larger story into sections we&rsquo;ll need to write a StoryParser which can parse an entire story file (for an example file, see <a href="http://blog.semanticart.com/blog/2014/01/11/writing-hypertext-fiction-in-markdown/">the previous post</a>). Again, this <a href="https://github.com/semanticart/cyoa-parser/blob/master/spec/story_parser_spec.rb">was TDD'ed</a>, but we&rsquo;ll cut to the chase:</p>

<p>```ruby
class StoryParser &lt; Parslet::Parser
  rule(:space) { match(&lsquo;\s&rsquo;).repeat }
  rule(:newline) { match(&lsquo;\n&rsquo;) }</p>

<p>  rule(:heading) { match(&lsquo;^#&rsquo;) >> space.maybe >> (match[&lsquo;\n{&rsquo;].absent? >> any).repeat.as(:heading) >> id.maybe }
  rule(:id)      { str(&lsquo;{#&rsquo;) >> (str(&lsquo;}&rsquo;).absent? >> any).repeat.as(:id) >> str(&lsquo;}&rsquo;) }
  rule(:content) { ((id | heading).absent? >> any).repeat }
  rule(:section) { (heading >> space.maybe >> content.as(:content) >> space.maybe).as(:section) }</p>

<p>  rule(:tile_block) { (str(&lsquo;%&rsquo;) >> (newline.absent? >> any).repeat >> newline).repeat }</p>

<p>  rule(:story) { space.maybe >> tile_block.maybe >> space.maybe >> section.repeat }</p>

<p>  root(:story)
end
```</p>

<p>Now we can parse out each section&rsquo;s heading text, id, and content into a tree that looks something like this:</p>

<p>```
[
  {:section=>{</p>

<pre><code>:heading=&gt;"Something isn't right here. "@51,
:id=&gt;"intro"@81,
:content=&gt;"You hear a phone ringing.\n\n- [pick up phone](#phone)..."@89}
</code></pre>

<p>  },
  {:section=>{</p>

<pre><code>:heading=&gt;"You pick up the phone... "@210,
:id=&gt;"phone"@237,
:content=&gt;"It is your grandmother. You die.\n\n- [start over](#intro)"@245}
</code></pre>

<p>  },
  &hellip;
]
```</p>

<p>&ldquo;That&rsquo;s well and good,&rdquo; you say, &ldquo;but how do we turn that into something useful?&rdquo;</p>

<p>Enter Parslet&rsquo;s Transform class (and exit your remaining skepticism). <a href="http://kschiess.github.io/parslet/transform.html">Parslet::Transform</a> takes a tree and lets you convert it into whatever you want. The following code takes a section tree from above, cleans up some whitespace, and then returns an instantiated Section class based on the input.</p>

<p>```ruby
class SectionTransformer &lt; Parslet::Transform
  rule(section: subtree(:hash)) {</p>

<pre><code>hash[:content] = hash[:content].to_s.strip
hash[:heading] = hash[:heading].to_s.strip

if hash[:id].to_s.empty?
  hash.delete(:id)
else
  hash[:id] = hash[:id].to_s
end

Section.new(hash)
</code></pre>

<p>  }
end
```</p>

<p>Example of an instantiated <a href="https://github.com/semanticart/cyoa-parser/blob/master/lib/section.rb">Section</a>:</p>

<p>``` ruby
p SectionTransformer.new.apply(tree[0])</p>

<h1>&lt;Section:0x007fd6e5853298</h1>

<h1>@content=&ldquo;You hear a phone ringing.\n\n- <a href="#phone">pick up phone</a>\n- <a href="#ignore-phone">do not answer</a>\n- <a href="#fire">set yourself on fire</a>&rdquo;,</h1>

<h1>@heading=&ldquo;Something isn&rsquo;t right here.&rdquo;,</h1>

<h1>@id=&ldquo;intro&rdquo;,</h1>

<h1>@links=[&ldquo;phone&rdquo;, &ldquo;ignore-phone&rdquo;, &ldquo;fire&rdquo;]></h1>

<p>```</p>

<p>So now we have the building blocks for parsing a story into sections and then our Section class internally uses the LinkParser from above to determine where the section branches outward.</p>

<p>Let&rsquo;s finish this by encapsulating the entire story in a Story class:</p>

<p>``` ruby
class Story
  attr_reader :sections</p>

<p>  def initialize(file)</p>

<pre><code>@sections = parse_file(file)
</code></pre>

<p>  end</p>

<p>  def branches</p>

<pre><code>@_branches ||= BranchCruncher.new(@sections).traverse
</code></pre>

<p>  end</p>

<p>  def reachable</p>

<pre><code>branches.flatten.uniq
</code></pre>

<p>  end</p>

<p>  def unreachable</p>

<pre><code>@sections.map(&amp;:id) - reachable
</code></pre>

<p>  end</p>

<p>  def split!(path)</p>

<pre><code>branches.each do |branch|
  File.open(path + branch.join('-') + '.md', 'w') do |f|
    branch.each do |id|
      section = sections.detect{|s| s.id == id}
      f.puts "# #{section.heading} {##{section.id}}\n"
      f.puts section.content
      f.puts "\n\n"
    end
  end
end
</code></pre>

<p>  end</p>

<p>  private</p>

<p>  def parse_file(file)</p>

<pre><code>SectionTransformer.new.apply(StoryParser.new.parse(file.read))
</code></pre>

<p>  end
end
```</p>

<p>A few notes:</p>

<ul>
<li>You instantiate the Story class with a File object pointing to your story.</li>
<li>It parses out the sections</li>
<li>Then you can call methods to fill in the missing pieces of functionality we identified at the beginning of this post.</li>
</ul>


<p>``` ruby</p>

<h1>Which sections are orphaned?</h1>

<p>p story.unreachable</p>

<h1>=> [&lsquo;some-unreachable-page-id&rsquo;]</h1>

<h1>What branches are there in the book?</h1>

<p>p story.branches</p>

<h1>=> [ [&ldquo;intro&rdquo;, &ldquo;investigate&rdquo;, &ldquo;help&rdquo;], [&ldquo;intro&rdquo;, &ldquo;investigate&rdquo;, &ldquo;rescue&rdquo;, &ldquo;wake-up&rdquo;], [&ldquo;intro&rdquo;, &ldquo;investigate&rdquo;, &ldquo;grounded&rdquo;], [&ldquo;intro&rdquo;, &ldquo;grounded&rdquo;] ]</h1>

<h1>Let me read each narrative branch by splitting each branch into files</h1>

<p>story.split!(&lsquo;/tmp/&rsquo;)</p>

<h1>creates files in /tmp/ folder named for each section in a branch</h1>

<h1>e.g. intro-investigate-help.md</h1>

<h1>You can read through each branch and ensure you&rsquo;ve maintained a cohesive narrative.</h1>

<p>```</p>

<p>If you made it this far, you deserve a cookie and my undying affection. I&rsquo;m all out of cookies and any I had would be gluten-free anyway, so how about I just link you to the example code instead and we call it even?</p>

<p>Here&rsquo;s the <a href="https://github.com/semanticart/cyoa-parser">cyoa-parser on github</a>. It includes a <a href="https://github.com/semanticart/cyoa-parser/blob/master/examples/smell-ya-later.md">hilariously bad speed-story</a> I wrote for my son when he insisted on a CYOA bedtime story 10 minutes before bed.</p>

<p>If you&rsquo;d like to learn more about Parslet from someone who knows it better than me, check out <a href="http://www.confreaks.com/videos/2730-wickedgoodruby-writing-dsl-s-with-parslet">Jason Garber&rsquo;s Wicked Good Ruby talk</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Unicorn Pukes Serving Large Files]]></title>
    <link href="http://blog.semanticart.com/blog/blog/2013/08/29/unicorn-pukes-serving-large-files/"/>
    <updated>2013-08-29T13:46:00-04:00</updated>
    <id>http://blog.semanticart.com/blog/blog/2013/08/29/unicorn-pukes-serving-large-files</id>
    <content type="html"><![CDATA[<p>Earlier today I was getting this weird <a href="http://unicorn.bogomips.org/">unicorn</a> error on heroku when trying to serve a retina-sized image.</p>

<pre><code>ERROR -- : app error: undefined method `each' for nil:NilClass (NoMethodError)
ERROR -- : [..]/unicorn-4.6.3/lib/unicorn/http_response.rb:60:in `http_response_write'
ERROR -- : [..]/unicorn-4.6.3/lib/unicorn/http_server.rb:563:in `process_client'
ERROR -- : [..]/unicorn-4.6.3/lib/unicorn/http_server.rb:633:in `worker_loop'
ERROR -- : [..]/unicorn-4.6.3/lib/unicorn/http_server.rb:500:in `spawn_missing_workers'
ERROR -- : [..]/unicorn-4.6.3/lib/unicorn/http_server.rb:142:in `start'
ERROR -- : [..]/unicorn-4.6.3/bin/unicorn_rails:209:in `&lt;top (required)&gt;'
</code></pre>

<p>Weird, right?  But sure enough, whenever I tried to view some-image@2x.png, everything went terribly wrong.</p>

<p>Googling took too long to find an answer, so I&rsquo;m sharing my solution here in hopes that it helps someone else (oh, hai, google bot).</p>

<p>The issue is actually a bug in the version of rack-cache required by actionpack in Rails 3.2.14. Attempting to serve files larger than 1mb causes this error.</p>

<p>It has been <a href="https://github.com/rtomayko/rack-cache/issues/42">fixed</a>, but I had to require the master branch for rack-cache to resolve the problem.</p>

<p><code>ruby Gemfile
gem "rack-cache", github: "rtomayko/rack-cache"
gem "unicorn"
</code></p>

<p>No more error.</p>

<p>Now, the real solution is to not serve large images through unicorn on heroku. But hooking up a CDN is another problem for another time.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Letterpress Word Finder]]></title>
    <link href="http://blog.semanticart.com/blog/blog/2013/08/27/letterpress-word-finder/"/>
    <updated>2013-08-27T16:13:00-04:00</updated>
    <id>http://blog.semanticart.com/blog/blog/2013/08/27/letterpress-word-finder</id>
    <content type="html"><![CDATA[<p>In an attempt to start to blog more, here&rsquo;s a quick follow-up post on the <a href="http://blog.semanticart.com/blog/2012/11/18/quick-and-dirty-ocr-for-letterpress-and-other-tile-based-games/">previous Letterpress article</a>.</p>

<h3>Background</h3>

<p>As a reminder, here&rsquo;s how I outlined steps in creating a Letterpress solver:</p>

<ol>
<li>Take screenshot of game and import it into solver</li>
<li>Parse the board into a string of letters</li>
<li>Reduce a dictionary of valid words against those characters to find playable words</li>
<li>Optionally make recommendations of which word to play based on current board state and strategy. (i.e. don&rsquo;t be naive)</li>
</ol>


<p>We built step one (sort-of) and step two in the previous article, so let&rsquo;s move on to step three.</p>

<h3>Requirements</h3>

<p>We want our script to fulfill the following requirements:</p>

<ol>
<li>Accept the board letters via STDIN or commandline arguments.</li>
<li>Reduce the dictionary words against those letters.</li>
<li>Dump out matching words (without regard to board state/strategy).</li>
</ol>


<h3>Implementation</h3>

<p>We&rsquo;ll take either an argument or read STDIN and downcase it.</p>

<p><code>ruby
letters = (ARGV[0] || STDIN.read).downcase
</code></p>

<p>I don&rsquo;t have the official Letterpress dictionary (a quick googling will get you on the right track if you insist), but every good unix-y system has a dictionary file.</p>

<pre><code>$ cat /usr/share/dict/words | wc -l
235886
</code></pre>

<p>OK, that&rsquo;s a lot of words. Let&rsquo;s pull them in and downcase them too.
<code>ruby
words = File.read("/usr/share/dict/words").downcase.split("\n")
</code></p>

<p>Now, the only really interesting part: a method to determine if a word can be constructed from letters. I&rsquo;ve shamelessly borrowed a perfectly fast solution from <a href="http://stackoverflow.com/questions/11349544/ruby-optimize-the-comparison-of-two-arrays-with-duplicates">Stackoverflow</a>.
<code>ruby
def is_subset?(word, letters)
  !word.chars.find{|char| word.count(char) &gt; letters.count(char)}
end
</code></p>

<p>And now we reduce our words by those that match our letters</p>

<p><code>ruby
matching_words = words.select do |word|
  is_subset?(word, letters)
end
</code></p>

<p>And there&rsquo;s nothing left to do but dump them out.</p>

<p><code>ruby
puts matching_words.sort_by(&amp;:length)
</code></p>

<p>Here&rsquo;s the <a href="https://gist.github.com/semanticart/6346135">entire word generating script</a>.</p>

<p>And an example of using it with the board parser from the previous post:</p>

<pre><code>$ ruby -r ./board_parser -e "puts BoardParser.new('light.png').tiles.join" | ruby letter.rb | tail -n 10
hermodactyl
typhlectomy
cryohydrate
polydactyle
pterodactyl
crymotherapy
hydrolyzable
acetylthymol
overthwartly
protractedly
</code></pre>

<p>Excellent. Of course, not all words in your system&rsquo;s dictionary file may be playable, YMMV, etc.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Quick and Dirty OCR for Letterpress &amp; Other Tile-based Games]]></title>
    <link href="http://blog.semanticart.com/blog/blog/2012/11/18/quick-and-dirty-ocr-for-letterpress-and-other-tile-based-games/"/>
    <updated>2012-11-18T00:00:00-05:00</updated>
    <id>http://blog.semanticart.com/blog/blog/2012/11/18/quick-and-dirty-ocr-for-letterpress-and-other-tile-based-games</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/light.png" width="160" height="240" title="&lsquo;Light Theme Game Board&rsquo;" ></p>

<p>I&rsquo;ve been playing enough <a href="https://itunes.apple.com/us/app/letterpress-word-game/id526619424?mt=8">Letterpress</a> lately to realize that I&rsquo;m not great at it. This is super frustrating for me when this is a game that you could easily teach a computer to play.</p>

<p>I&rsquo;m not the first person to have that thought. There are plenty of cheating programs for Letterpress (just google or search in the app store).</p>

<p>I haven&rsquo;t investigated these solvers but in thinking about the problem, the basic approach would seem to be:</p>

<ul>
<li>Take screenshot of game and import it into solver</li>
<li>Parse the board into a string of letters</li>
<li>Reduce a dictionary of valid words against those characters to find playable words</li>
<li>Optionally make recommendations of which word to play based on current board state and strategy.</li>
</ul>


<p>I wondered how quickly I could throw something together to simply parse the game board into a string of letters. It turns out it is super easy. To get started I took a screenshot of a game in progress and downloaded it from my phone.</p>

<!--more-->


<p>I&rsquo;d heard about <a href="https://code.google.com/p/tesseract-ocr/">tesseract</a> back when it was first announced and it seemed worth giving it a shot. I started with <code>brew install tesseract</code> and tried simply passing in the board image unmodified:</p>

<pre><code>$ tesseract light.png /tmp/output
$ cat /tmp/output.txt
R
QM V
66:
KO
</code></pre>

<p>Not even close. The homebrew instructions recommend grayscaling the image first with <a href="http://www.imagemagick.org/script/index.php">ImageMagick</a>, so what do we get after that?</p>

<pre><code>$ convert light.png -type Grayscale /tmp/gray.tif
$ tesseract /tmp/gray.tif /tmp/output
$ cat /tmp/output.txt

QM
V
w
Aâ€˜ K
6'
</code></pre>

<p><strong>Ugh</strong>, even worse.<a href="#tesseract-parsing-footnote"><sup>1</sup></a></p>

<p>But poking through tesseract&rsquo;s options reveal some promise via pagesegmode settings:</p>

<pre><code>7 = Treat the image as a single text line.
</code></pre>

<p>and</p>

<pre><code>10 = Treat the image as a single character.
</code></pre>

<p>7 turned out to be a bust, but after testing option 10 on a few individual tiles, things were starting to look up. So let&rsquo;s just break the image up into the individual 25 tiles and recognize each one.</p>

<p>There may be more elegant ways to break the image into tiles, but I ended up using two ImageMagick commands:</p>

<p>``` sh</p>

<h1>remove the non-tile content (i.e. the scores, etc. in the header)</h1>

<p>convert light.png -gravity North -chop 0x320 /tmp/headless.png</p>

<h1>break the tile-content into 128x128px chunks</h1>

<p>convert /tmp/headless.png -crop 128x128 /tmp/tile_%02d.png
```</p>

<p>Then I wrapped these two commands up in a <a href="https://github.com/semanticart/letterpress-board-parser/blob/master/board_parser.rb">ruby class for ease of use</a> and wrote <a href="https://github.com/semanticart/letterpress-board-parser/blob/master/test/board_parser_test.rb">a simple test</a>.</p>

<p>so, running the ruby class:</p>

<p><code>bash
$ ruby -r ./board_parser -e "puts BoardParser.new('light.png').tiles.join"
KTVHROBDRBDLCYTPLEWAFZYMB
</code></p>

<p>Bingo! A perfect match, ready to be compared to a dictionary of valid words.</p>

<p>It turns out tesseract is great at matching single tiles regardless of color scheme or captured state of the tile. The tests for the code run against screenshots from all available color schemes.</p>

<p>This approach is dead-simple and leans heavily on solid existing technologies. Because of this, the glue code itself doesn&rsquo;t have to be clever at all :)</p>

<p>Note that this quick hack is just designed to work against iPhone 4 resolution screenshots -you would have to (at least) change the header crop size for iPhone 5.</p>

<hr />


<p id="tesseract-parsing-footnote">1: The recommendation to convert the image to grayscale is a good hint that tesseract probably relies a lot on consistent contrast. This coupled with the fact that we're dealing with random letters instead of words definitely stacks the cards against tesseract. Dealing with individual tiles/characters solves both the confusion of multiple contrasts and the confusion of dealing with random gibberish.</p>



]]></content>
  </entry>
  
</feed>
